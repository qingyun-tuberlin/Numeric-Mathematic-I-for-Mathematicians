{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d7d24a1",
   "metadata": {},
   "source": [
    "# project 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26520172",
   "metadata": {},
   "source": [
    "## set up"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "003921b8",
   "metadata": {},
   "source": [
    "### step 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2783c39b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 0\n",
    "# I use macbook. I have created a folder for this project, then I create a virtal environment for \n",
    "# the python code.\n",
    "# If you also use Macbook, here is the command I have used\n",
    "# cd /path/to/your_project\n",
    "# python3 -m venv .venv\n",
    "# source .venv/bin/activate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f47f52",
   "metadata": {},
   "source": [
    "### step 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f59db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 1: upgrade pip, skip this step if you already upgraded pip\n",
    "# pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "202884dd",
   "metadata": {},
   "source": [
    "### step 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b684bfa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 2: install relevant packages, kip this step if you already have insatlled them\n",
    "# !pip install numpy\n",
    "# !pip install scikit-learn\n",
    "# !pip install matplotlib\n",
    "# !pip install scikit-image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8cf9429",
   "metadata": {},
   "source": [
    "## my solution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44789a7e",
   "metadata": {},
   "source": [
    "### import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "55eb6185",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the relevant packages\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import io, color \n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "204c8087",
   "metadata": {},
   "outputs": [],
   "source": [
    "# global variables which is speicfied in the task description\n",
    "n0 = 28 # input dimention\n",
    "n1 = 64 # hidden layer 1\n",
    "n2 = 32 # hidden layer 2\n",
    "n3 = 3  # output dimention"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2cfb8e6",
   "metadata": {},
   "source": [
    "### load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f3454e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Load MNIST digits\n",
    "digits = load_digits()\n",
    "X = digits.data               # shape: (543, 64)\n",
    "y = digits.target             # shape: (543,)\n",
    "\n",
    "# 2. Filter classes (1,5,7)\n",
    "# if the entity in y is 1, 5, or y, then the value true will be stored\n",
    "# in the mask.\n",
    "# otherwise, it will store False.\n",
    "mask = np.isin(y, [1, 5, 7])\n",
    "X = X[mask]\n",
    "y = y[mask]\n",
    "\n",
    "# map labels to {0,1,2}\n",
    "# label_map is an dictionary,\n",
    "# previously, the entity in the y represents classes, its value is 0,1,...9\n",
    "# we only concern about classes 1,5,7,\n",
    "# therefore, we do mapping on them\n",
    "label_map = {1:0, 5:1, 7:2}\n",
    "y = np.array([label_map[v] for v in y])\n",
    "\n",
    "# 3. Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# 4. Standardize\n",
    "# standardize formular: z = (x - u)/sigma\n",
    "# u: mean, sigma:\n",
    "# here, scaler is an empty object, it has no idea about\n",
    "# how data looks like\n",
    "scaler = StandardScaler()\n",
    "# fit_transform does 2 tasks:\n",
    "# 1) fit: calculate the mean u and std sigma of each colum\n",
    "# 2) transform: apply the standardize formular(z = (x - u)/sigma)\n",
    "# on each element of the matrix\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "\n",
    "# here, we should only use transform, because the test data set can not\n",
    "# use its own mean and std, it should use the u and sigma of the training\n",
    "# data set\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "115a3390",
   "metadata": {},
   "source": [
    "### utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d3f6c46e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the task description:\n",
    "# one_hot encoding, mit Ausgabe eines Binären 3-dimensionalen Arrays,\n",
    "# wie habe y samples, K categories\n",
    "# each row means to which category does the sample belong to\n",
    "def one_hot(y, K=3):\n",
    "    N = len(y)\n",
    "    Y = np.zeros((N, K))\n",
    "    Y[np.arange(N), y] = 1\n",
    "    return Y\n",
    "\n",
    "def test_one_hot():\n",
    "    # Test\n",
    "    # the example below shows how is the input and output \n",
    "    # when you use one_hot function\n",
    "    y = np.array([2,1,0,2])\n",
    "    Y = np.zeros((4,3))\n",
    "    print(Y)\n",
    "    result = one_hot(y)\n",
    "    print(result)\n",
    "    \"\"\"     [[0. 0. 0.]\n",
    "            [0. 0. 0.]\n",
    "            [0. 0. 0.]\n",
    "            [0. 0. 0.]]\n",
    "\n",
    "            [[0. 0. 1.]\n",
    "            [0. 1. 0.]\n",
    "            [1. 0. 0.]\n",
    "            [0. 0. 1.]]\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "24d4a95f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# how I got this formula, \n",
    "# please read the softplus function herleiten.jpg, that is my note\n",
    "def softplus(x):\n",
    "    return np.log1p(np.exp(-np.abs(x))) + np.maximum(x, 0)\n",
    "\n",
    "# derivative of log(1+exp(x)) = derivative(1+exp(x)) * (1/(1+exp(x)))\n",
    "def d_softplus(x):\n",
    "    return 1 / (1 + np.exp(-x))   # sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5eb8bdb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "# concrete steps of proof/calculating\n",
    "# please read the derivative of sigmoid herleiten.jpg. that is my note\n",
    "def d_sigmoid(x):\n",
    "    s = sigmoid(x)\n",
    "    return s * (1 - s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87e5f47b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the dimention of z is : (N,K)\n",
    "# because the task gives: we use the one-hot encoded labels\n",
    "# the output of a one-hot encoed is (N，K)\n",
    "def softmax(z):\n",
    "    # first, substract the maximum item of each row,\n",
    "    # rowwise substraction, hence, axis = 1\n",
    "    z_shifted = z - np.max(z,axis=1,keepdims=True)\n",
    "\n",
    "    # then, we want to calculate the exponentional value of each item\n",
    "    exp_z = np.exp(z_shifted)\n",
    "    # sum up the exponential value\n",
    "    sum_exp_z = np.sum(exp_z,axis=1,keepdims=True)\n",
    "    # each item divde itself by sum-up value, it gives possibility\n",
    "    probabilities = exp_z / sum_exp_z\n",
    "    return probabilities\n",
    "\n",
    "def cross_entropy_loss():\n",
    "    pass\n",
    "\n",
    "def mse_loss(logits,Y):\n",
    "    pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24a1af40",
   "metadata": {},
   "source": [
    "### build up multilayer perceptron (MLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e4ddf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP:\n",
    "    def __init__(self, D, n1=64, n2=32, K=3, seed=0):\n",
    "        rng = np.random.default_rng(seed)\n",
    "\n",
    "        self.W1 = rng.normal(0, 0.01, (D, n1))\n",
    "        self.b1 = np.zeros((1, n1))\n",
    "\n",
    "        self.W2 = rng.normal(0, 0.01, (n1, n2))\n",
    "        self.b2 = np.zeros((1, n2))\n",
    "\n",
    "        self.W3 = rng.normal(0, 0.01, (n2, K))\n",
    "        self.b3 = np.zeros((1, K))\n",
    "\n",
    "    def forward(self, X):\n",
    "        self.X  = X\n",
    "        self.z1 = X @ self.W1 + self.b1\n",
    "        self.a1 = softplus(self.z1)\n",
    "\n",
    "        self.z2 = self.a1 @ self.W2 + self.b2\n",
    "        self.a2 = softplus(self.z2)\n",
    "\n",
    "        self.z3 = self.a2 @ self.W3 + self.b3\n",
    "        return self.z3            # logits\n",
    "\n",
    "    def backward(self, grad_out):\n",
    "        dW3 = self.a2.T @ grad_out\n",
    "        db3 = np.sum(grad_out, axis=0, keepdims=True)\n",
    "\n",
    "        da2 = grad_out @ self.W3.T\n",
    "        dz2 = da2 * d_softplus(self.z2)\n",
    "\n",
    "        dW2 = self.a1.T @ dz2\n",
    "        db2 = np.sum(dz2, axis=0, keepdims=True)\n",
    "\n",
    "        da1 = dz2 @ self.W2.T\n",
    "        dz1 = da1 * d_softplus(self.z1)\n",
    "\n",
    "        dW1 = self.X.T @ dz1\n",
    "        db1 = np.sum(dz1, axis=0, keepdims=True)\n",
    "\n",
    "        return dW1, db1, dW2, db2, dW3, db3\n",
    "\n",
    "    def update(self, grads, lr=0.01):\n",
    "        dW1, db1, dW2, db2, dW3, db3 = grads\n",
    "\n",
    "        self.W1 -= lr * dW1\n",
    "        self.b1 -= lr * db1\n",
    "        self.W2 -= lr * dW2\n",
    "        self.b2 -= lr * db2\n",
    "        self.W3 -= lr * dW3\n",
    "        self.b3 -= lr * db3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ca8fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def softmax(z):\n",
    "    z = z - np.max(z, axis=1, keepdims=True)\n",
    "    expz = np.exp(z)\n",
    "    return expz / np.sum(expz, axis=1, keepdims=True)\n",
    "\n",
    "def cross_entropy_loss(logits, Y):\n",
    "    P = softmax(logits)\n",
    "    loss = -np.sum(Y * np.log(P + 1e-9)) / len(Y)\n",
    "    grad = (P - Y) / len(Y)    # dL/dz3\n",
    "    return loss, grad\n",
    "\n",
    "# 2. 初始化模型\n",
    "D = X_train.shape[1]\n",
    "model = MLP(D=D, n1=64, n2=32, K=3)\n",
    "\n",
    "Y_train = one_hot(y_train)\n",
    "Y_test  = one_hot(y_test)\n",
    "\n",
    "# 3. 训练循环（full batch）\n",
    "epochs = 50\n",
    "lr = 0.01\n",
    "\n",
    "for ep in range(epochs):\n",
    "    logits = model.forward(X_train)\n",
    "    loss, grad_out = cross_entropy_loss(logits, Y_train)\n",
    "\n",
    "    grads = model.backward(grad_out)\n",
    "    model.update(grads, lr=lr)\n",
    "\n",
    "    # evaluate\n",
    "    test_logits = model.forward(X_test)\n",
    "    test_pred = np.argmax(test_logits, axis=1)\n",
    "    acc = accuracy_score(y_test, test_pred)\n",
    "\n",
    "    print(f\"epoch {ep:03d} | loss={loss:.4f} | test_acc={acc:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a28741",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_full_batch(model, \n",
    "                     X_train, y_train, \n",
    "                     X_test, y_test, \n",
    "                     loss_fn,      # z.B. cross_entropy_loss\n",
    "                     epochs=50,\n",
    "                     lr=0.01):\n",
    "\n",
    "    Y_train = one_hot(y_train)\n",
    "    Y_test  = one_hot(y_test)\n",
    "\n",
    "    train_losses = []\n",
    "    test_losses  = []\n",
    "    test_accs    = []\n",
    "\n",
    "    for ep in range(epochs):\n",
    "\n",
    "        # ---- Forward ----\n",
    "        logits = model.forward(X_train)\n",
    "\n",
    "        # ---- Loss + Grad ----\n",
    "        train_loss, grad_out = loss_fn(logits, Y_train)\n",
    "\n",
    "        # ---- Backward ----\n",
    "        grads = model.backward(grad_out)\n",
    "\n",
    "        # ---- Update ----\n",
    "        model.update(grads, lr)\n",
    "\n",
    "        # ---- Evaluate on test ----\n",
    "        test_logits = model.forward(X_test)\n",
    "        test_loss, _ = loss_fn(test_logits, Y_test)\n",
    "\n",
    "        y_pred = np.argmax(test_logits, axis=1)\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "        train_losses.append(train_loss)\n",
    "        test_losses.append(test_loss)\n",
    "        test_accs.append(acc)\n",
    "\n",
    "        print(f\"Epoch {ep:03d} | \"\n",
    "              f\"Train Loss={train_loss:.4f} | \"\n",
    "              f\"Test Loss={test_loss:.4f} | \"\n",
    "              f\"Test Acc={acc:.3f}\")\n",
    "\n",
    "    return train_losses, test_losses, test_accs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d135a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss(train_losses, test_losses):\n",
    "    plt.figure(figsize=(7,5))\n",
    "    plt.plot(train_losses, label=\"Train Loss\")\n",
    "    plt.plot(test_losses, label=\"Test Loss\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.title(\"Loss über die Epochen\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b52eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix_matplotlib(model, X_test, y_test,\n",
    "                                     class_names=None):\n",
    "    \"\"\"\n",
    "    Zeichnet die Confusion-Matrix nur mit matplotlib.\n",
    "    class_names: Liste wie [\"1\",\"5\",\"7\"] oder [\"0\",\"1\",\"2\"]\n",
    "    \"\"\"\n",
    "    # Vorhersage\n",
    "    logits = model.forward(X_test)\n",
    "    y_pred = np.argmax(logits, axis=1)\n",
    "\n",
    "    # Confusion-Matrix berechnen\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    plt.figure(figsize=(5,4))\n",
    "    plt.imshow(cm, interpolation=\"nearest\", cmap=plt.cm.Blues)\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.colorbar()\n",
    "\n",
    "    # Achsen-Beschriftung\n",
    "    if class_names is None:\n",
    "        classes = np.arange(cm.shape[0])\n",
    "    else:\n",
    "        classes = class_names\n",
    "\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    plt.xlabel(\"Predicted label\")\n",
    "    plt.ylabel(\"True label\")\n",
    "\n",
    "    # Zahlen in die Kästchen schreiben\n",
    "    thresh = cm.max() / 2.0\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            plt.text(j, i, str(cm[i, j]),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a83c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练\n",
    "train_losses, test_losses, test_accs = train_full_batch(\n",
    "    model,\n",
    "    X_train, y_train,\n",
    "    X_test, y_test,\n",
    "    loss_fn=cross_entropy_loss,\n",
    "    epochs=50,\n",
    "    lr=0.01\n",
    ")\n",
    "\n",
    "# 绘制 Loss 曲线\n",
    "plot_loss(train_losses, test_losses)\n",
    "\n",
    "# 绘制 Confusion-Matrix\n",
    "plot_confusion_matrix_matplotlib(model, X_test, y_test,\n",
    "                                 class_names=[\"1\", \"5\", \"7\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
